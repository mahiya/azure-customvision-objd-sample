{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Custom Vision を使った物体検知モデルの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各種設定を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成する Azure Custom Vision のプロジェクト名を指定する\n",
    "acv_project_name = \"Sample Project\"\n",
    "\n",
    "# アノテーションファイルが格納されているフォルダパスを指定する\n",
    "annotations_dir_path = \"annotations\"\n",
    "\n",
    "# Custom Vision のアクセス情報ファイルのパスを指定する\n",
    "acv_config_path = \"acv_config.json\"\n",
    "\n",
    "# 作成した分析モデル(ONNX)や動画の分析結果を格納するフォルダパスを指定する\n",
    "outputs_dir_path = \"outputs\"\n",
    "\n",
    "# 分析に使用するビデオファイルのパス\n",
    "video_file_path = \"sample_video.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VoTTから出力されたアノテーションファイル(.json)を読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "json_file_paths = glob.glob(f\"{annotations_dir_path}/*.json\")\n",
    "vott_images = []\n",
    "for json_file_path in json_file_paths:\n",
    "    with open(json_file_path, \"r\") as f:\n",
    "        vott_image = json.load(f)\n",
    "        vott_images.append(vott_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Vision プロジェクトの使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作成した Custom Vision のエンドポイントとキーを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(acv_config_path, \"r\") as f:\n",
    "    acv_config = json.load(f)\n",
    "\n",
    "acv_endpoint = acv_config[\"endpoint\"]\n",
    "acv_key = acv_config[\"key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Vision へのアクセスクライアントを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": acv_key})\n",
    "client = CustomVisionTrainingClient(acv_endpoint, credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロジェクトを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成するプロジェクトと同一の名前のプロジェクトが既に存在している場合は削除する\n",
    "for exist_project in list(filter(lambda x: x.name == acv_project_name, client.get_projects())):\n",
    "    client.delete_project(exist_project.id)\n",
    "\n",
    "# ドメイン (プロジェクトタイプ) を取得する\n",
    "domain_type = \"ObjectDetection\"\n",
    "domain_name = \"General (compact)\"\n",
    "\n",
    "# プロジェクトを作成する\n",
    "domain = next(domain for domain in client.get_domains() if domain.type == domain_type and domain.name == domain_name)\n",
    "project = client.create_project(acv_project_name, domain_id=domain.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 後に使用する関数を定義\n",
    "Custom Vision プロジェクトには1API呼び出しにつき最大64枚の画像がアップロード可能であるため、64枚ずつ画像のアップロード処理を行うために使用する、配列(画像のファイルパス)を64個ごとに分割するための関数を用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配列を指定したサイズの配列の配列に変換する関数を定義\n",
    "# in: ([1,2,3,4,5], 2) -> out: [[1,2],[3,4],[5]]\n",
    "def generate_chunks(arr, size):\n",
    "    chunks = []\n",
    "    index = 0\n",
    "    while True:\n",
    "        chunk = arr[index : index + size]\n",
    "        if len(chunk) == 0:\n",
    "            break\n",
    "        chunks.append(chunk)\n",
    "        index += size\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロジェクトにタグと画像を追加する\n",
    "Custom Vision プロジェクトにタグを追加して、そのタグに対応する画像をアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "\n",
    "# 一度にアップロードできる画像枚数が最大64枚であるため、配列を64画像ごとの配列に変換する\n",
    "chunks = generate_chunks(vott_images, 64)\n",
    "\n",
    "# 作成したタグ一覧\n",
    "tags = {} # Key: tag name, Value: tag instance\n",
    "\n",
    "# 画像64枚ごとに処理を行う\n",
    "for chunk in chunks:\n",
    "    upload_images = []\n",
    "    for vott_image in chunk:\n",
    "        image_file_path = vott_image['asset']['path'].replace(\"file:\", \"\")\n",
    "        image_width = vott_image['asset']['size']['width']\n",
    "        image_height = vott_image['asset']['size']['height']\n",
    "        vott_regions = vott_image['regions']\n",
    "\n",
    "        # タグを作成する\n",
    "        for region in vott_regions:\n",
    "            for tag_name in region['tags']:\n",
    "                if tag_name not in tags:\n",
    "                    print(f\"add tag: {tag_name}\")\n",
    "                    tag = client.create_tag(project.id, tag_name)\n",
    "                    tags[tag_name] = tag\n",
    "        \n",
    "        # リージョン指定を行う\n",
    "        regions = []\n",
    "        for vott_region in vott_regions:\n",
    "            bounding_box = vott_region['boundingBox']\n",
    "            for tag_name in vott_region['tags']:\n",
    "                region = Region(tag_id=tags[tag_name].id, left=bounding_box['left'] / image_width, top=bounding_box['top'] / image_height, width=bounding_box['width'] / image_width, height=bounding_box['height'] / image_height)\n",
    "                regions.append(region)\n",
    "\n",
    "        # 画像ファイルを指定する\n",
    "        with open(image_file_path, \"rb\") as image_contents:\n",
    "            upload_image = ImageFileCreateEntry(name=os.path.basename(image_file_path), contents=image_contents.read(), regions=regions)\n",
    "            upload_images.append(upload_image)\n",
    "                \n",
    "    # 画像をまとめてアップロードする\n",
    "    print(f'upload {len(upload_images)} images')\n",
    "    client.create_images_from_files(project.id, ImageFileCreateBatch(images=upload_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニングを開始する\n",
    "Quick Training でトレーニングを開始します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = client.train_project(project.id)\n",
    "print(f\"training got started: {iteration.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニングが終了するまで待機する\n",
    "トレーニングは約3分で完了します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while iteration.status != \"Completed\":\n",
    "    iteration = client.get_iteration(project.id, iteration.id)\n",
    "    # print(\"Training status: \" + iteration.status)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完了したトレーニング結果のエクスポートを開始する\n",
    "トレーニングにて作成された分析モデルをダウンロードするため、まずエクスポートリクエストを行います。リクエストをすると、Azure Custom Vision 側でユーザがダウンロード可能なファイルを用意してくれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training.models import CustomVisionErrorException\n",
    "\n",
    "platform = \"ONNX\"\n",
    "try:\n",
    "    exported = client.export_iteration(project.id, iteration.id, platform=platform)\n",
    "except CustomVisionErrorException as e:\n",
    "    # 既にエクスポートが実行されている場合は例外をスローしない\n",
    "    if e.message != f\"{iteration.id} is already queued for export\":\n",
    "        raise (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### エクスポートが完了するまで待機する\n",
    "エクスポート準備には数秒の時間がかかるため、エクスポート準備が完了するまで待機を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    exports = client.get_exports(project.id, iteration.id)\n",
    "    export = list(filter(lambda x: x.platform == platform, exports))[0]\n",
    "    if export.download_uri is not None:\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果を出力するフォルダを再生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "if os.path.exists(outputs_dir_path):\n",
    "    shutil.rmtree(outputs_dir_path)\n",
    "os.makedirs(outputs_dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### エクスポートされたモデルをダウンロードしてローカルに保存する\n",
    "Custom Vision で作成された分析モデルをダウンロードして、作業フォルダに```model.onnx```と```labels.txt```を格納します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# ZIPファイルをダウンロードする\n",
    "downloaded = requests.get(export.download_uri).content\n",
    "model_zip_path = f\"{outputs_dir_path}/exported_model.zip\"\n",
    "with open(model_zip_path, \"wb\") as f:\n",
    "    f.write(downloaded)\n",
    "\n",
    "model_dir_path = f\"{outputs_dir_path}/exported_model\"\n",
    "model_file_path = f\"{outputs_dir_path}/model.onnx\"\n",
    "labels_file_path = f\"{outputs_dir_path}/labels.txt\"\n",
    "\n",
    "# ZIPファイルを解凍する\n",
    "shutil.unpack_archive(model_zip_path, model_dir_path)\n",
    "\n",
    "# 必要なファイルのみを作業フォルダにコピーする\n",
    "shutil.move(f\"{model_dir_path}/model.onnx\", model_file_path)\n",
    "shutil.move(f\"{model_dir_path}/labels.txt\", labels_file_path)\n",
    "\n",
    "# ZIPファイル解凍で作成されたフォルダを削除する\n",
    "shutil.rmtree(model_dir_path)\n",
    "\n",
    "# ZIPファイルを削除する\n",
    "os.remove(model_zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析モデルを使った動画の分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析モデルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.onnx_obj_detection_model import OnnxObjectDetectionModel\n",
    "\n",
    "# 物体検知モデルのラベルを読み込む\n",
    "with open(labels_file_path, \"r\") as f:\n",
    "    labels = [l.strip() for l in f.readlines()]\n",
    "\n",
    "# 物体検知モデルを読み込む\n",
    "model = OnnxObjectDetectionModel(model_file_path, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定したビデオの各フレームに物体検知分析を行い、物体検知結果を追加したビデオを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# 物体検知結果を追加したビデオを出力するファイルパス\n",
    "output_video_path = f\"{outputs_dir_path}/analyzed_video.mp4\"\n",
    "\n",
    "# 画像分析に使用する一時ファイルのパス\n",
    "tmp_file_path = \"tmp.jpg\"  \n",
    "\n",
    "# 出力先の動画を用意する\n",
    "fourcc = cv2.VideoWriter_fourcc(\"m\", \"p\", \"4\", \"v\")\n",
    "video = cv2.VideoWriter(output_video_path, fourcc, 20.0, (1920, 1080))\n",
    "\n",
    "# 動画からフレームを取得する\n",
    "cap = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "# 動画のフレームごとに処理を行う\n",
    "frame = 0\n",
    "while True:\n",
    "    print(f\"process frame {frame}\")\n",
    "    ret, image = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 指定された画像に対して物体検知の推論を行う\n",
    "    cv2.imwrite(tmp_file_path, image)\n",
    "    results = model.predict_image(Image.open(tmp_file_path))\n",
    "    print(results)\n",
    "\n",
    "    # 各タグでも最も確度(Probability)が高い結果のみを使用する\n",
    "    predictions = {}\n",
    "    for result in results:\n",
    "        if result[\"tagName\"] not in predictions or predictions[result[\"tagName\"]][\"probability\"] < result[\"probability\"]:\n",
    "            predictions[result[\"tagName\"]] = {\n",
    "                \"probability\": result[\"probability\"],\n",
    "                \"left\": result[\"boundingBox\"][\"left\"],\n",
    "                \"top\": result[\"boundingBox\"][\"top\"],\n",
    "                \"width\": result[\"boundingBox\"][\"width\"],\n",
    "                \"height\": result[\"boundingBox\"][\"height\"],\n",
    "            }\n",
    "\n",
    "\n",
    "    # 検知した各物体(タグ)を赤枠で囲って確度を表示する\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    for tag in predictions.keys():\n",
    "        prediction = predictions[tag]\n",
    "        left = max(int(prediction[\"left\"] * image_width), 0)\n",
    "        top = max(int(prediction[\"top\"] * image_height), 0)\n",
    "        width = int(prediction[\"width\"] * image_width)\n",
    "        height = int(prediction[\"height\"] * image_height)\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (left, top),\n",
    "            (left + width, top + height),\n",
    "            (0, 0, 255),\n",
    "            thickness=2,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            f\"{tag} ({round(prediction['probability'], 2)})\",\n",
    "            (left, max(top - 10, 0)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1.0,\n",
    "            (0, 0, 255),\n",
    "            thickness=2,\n",
    "        )\n",
    "\n",
    "    # 出力ビデオにフレームを追加する\n",
    "    video.write(image)\n",
    "\n",
    "    frame += 1\n",
    "\n",
    "# 動画を出力する\n",
    "video.release()\n",
    "\n",
    "# 一時画像ファイルを削除する\n",
    "if os.path.isfile(tmp_file_path):\n",
    "    os.remove(tmp_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env_acv_sample')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf77e490be843259981738df651ad75e7cb4a9b1c88a0a7f212a4d560e1889e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
