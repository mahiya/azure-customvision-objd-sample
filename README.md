# About this repository
This repository stores Python codes and Jupyter Notebook for creating an object detection model using Azure Custom Vision and analyzing a video, outputting the result as a video. Each code does the followings:

- create_acv_account.sh
  - Creating Azure resource group
  - Creating Azure Custom Vision account
  - Outputting an endpoint and a key of created Azure Custom Vision account as a file (acv_config.json)
- create_model_by_acv.ipynb
  - Creating Azure Custom Vision project
  - Uploading images and adding tags to the project
  - Starting training on the project
  - Downloading ONNX model generated by the training
  - Using ONNX model generated by the training
- extract_frames_from_video.py
  - Outputting each frame from a video file as image files

> An annotation file is expected to be generated by [VoTT](https://github.com/microsoft/VoTT)


## Required tools
- [Azure CLI](https://docs.microsoft.com/ja-jp/cli/azure/install-azure-cli)
- [Anaconda](https://www.anaconda.com/products/distribution)

# How to use

Login to Azure tenant by Azure CLI, and select Azure subscription to use.
```bash
az login
az account set --subscription "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
```

Run the following command to prepare images and create Azure Custom Vision account.

```bash
# Create Python virtual environment by Anaconda
conda env create
conda activate env_acv_sample

# Generate each frames image files from a video file
python extract_frames_from_video.py sample_video.mp4 images

# Create Azure Custom Vision account
./create_acv_account.sh rg-acv-sample acv-sample
```

Run Jupyter Notebook ```create_model_by_acv.ipynb``` on a kernel of created Python environment ```env_acv_sample```.

# Expected result video

![Outputted video as an analysis result](.images/analyzed_video.gif)
